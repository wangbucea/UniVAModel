import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from VLAModel import RobotUniADModel
import matplotlib.pyplot as plt
from tqdm import tqdm

def generate_random_data(batch_size=4, device='cuda'):
    """
    ç”Ÿæˆéšæœºè®­ç»ƒæ•°æ®
    """
    # è¾“å…¥å›¾åƒ: [B, T, C, H, W]
    images = torch.randn(batch_size, 2, 3, 640, 480).to(device)
    
    # è¾“å…¥åŠ¨ä½œåºåˆ—: [B, seq_len, action_dim] - ç”¨äºè‡ªå›å½’æ¨¡å‹çš„ç‰¹å¾ç¼–ç 
    input_actions = torch.randn(batch_size, 30, 7).to(device)
    
    # ç›®æ ‡åŠ¨ä½œåºåˆ—: [B, seq_len, action_dim]
    target_actions = torch.randn(batch_size, 30, 7).to(device)
    
    # è¯­ä¹‰åˆ†å‰²æ©ç : [B, H, W]
    seg_masks = torch.randint(0, 1, (batch_size, 480, 640)).to(device)
    
    # æ£€æµ‹ç›®æ ‡ï¼ˆDETRæ ¼å¼ï¼‰
    det_targets = []
    for i in range(batch_size):
        num_objects = np.random.randint(1, 6)  # æ¯å¼ å›¾1-5ä¸ªç›®æ ‡
        target = {
            'labels': torch.randint(0, 10, (num_objects,)).to(device),
            'boxes': torch.rand(num_objects, 4).to(device)  # [x_center, y_center, width, height] å½’ä¸€åŒ–åæ ‡
        }
        det_targets.append(target)
    
    # æŠ“å–ç‚¹åæ ‡: [B, num_points, 7]
    point_coords = torch.rand(batch_size, 3, 7).to(device)  # 3ä¸ªæŠ“å–ç‚¹
    
    targets = {
        'seg_masks': seg_masks,
        'det_targets': det_targets,
        'point_coords': point_coords,
        'actions': target_actions
    }
    
    return images, input_actions, target_actions, targets

def test_model_training():
    """
    æµ‹è¯•æ¨¡å‹è®­ç»ƒè¿‡ç¨‹
    """
    print("å¼€å§‹VLAæ¨¡å‹è®­ç»ƒéªŒè¯...")
    
    # è®¾å¤‡è®¾ç½®
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ¨¡å‹
    model = RobotUniADModel(
        num_seg_classes=1,
        num_det_classes=10,
        num_seg_queries=50,
        num_det_queries=50,
        num_points=3,
        action_dim=7,
        seq_len=30,
        image_size=(640, 480)
    ).to(device)
    
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
    
    # ä¼˜åŒ–å™¨
    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)
    
    # è®­ç»ƒå¾ªç¯
    model.train()
    num_epochs = 1
    num_batches = 10
    
    loss_history = []
    
    print("\nå¼€å§‹è®­ç»ƒå¾ªç¯...")
    for epoch in range(num_epochs):
        epoch_losses = []
        
        with tqdm(range(num_batches), desc=f"Epoch {epoch+1}/{num_epochs}") as pbar:
            for batch_idx in pbar:
                # ç”Ÿæˆéšæœºæ•°æ®
                images, input_actions, target_actions, targets = generate_random_data(batch_size=2, device=device)
                
                # å‰å‘ä¼ æ’­ - ä½¿ç”¨æ–°çš„è‡ªå›å½’æ¨¡å‹æ¥å£
                try:
                    outputs = model(images, input_actions, target_actions)
                    
                    # è®¡ç®—æŸå¤±
                    losses = model.compute_loss(outputs, targets)
                    total_loss = losses['total_loss']
                    
                    # åå‘ä¼ æ’­
                    optimizer.zero_grad()
                    total_loss.backward()
                    
                    # æ¢¯åº¦è£å‰ª
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    
                    optimizer.step()
                    
                    # è®°å½•æŸå¤±
                    epoch_losses.append(total_loss.item())
                    loss_history.append(total_loss.item())
                    
                    # æ›´æ–°è¿›åº¦æ¡
                    pbar.set_postfix({
                        'Loss': f'{total_loss.item():.4f}',
                        'Seg': f'{losses.get("seg_loss", 0):.4f}',
                        'Det': f'{losses.get("loss_ce", 0):.4f}',
                        'Point': f'{losses.get("point_loss", 0):.4f}',
                        'Traj': f'{losses.get("trajectory_loss", 0):.4f}'
                    })
                    
                except Exception as e:
                    print(f"\nè®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
                    import traceback
                    traceback.print_exc()
                    return False
        
        avg_loss = np.mean(epoch_losses)
        print(f"Epoch {epoch+1} å¹³å‡æŸå¤±: {avg_loss:.4f}")
    
    # æµ‹è¯•æ¨ç†æ¨¡å¼
    print("\næµ‹è¯•æ¨ç†æ¨¡å¼...")
    model.eval()
    with torch.no_grad():
        try:
            test_images = torch.randn(1, 2, 3, 640, 480).to(device)
            test_input_actions = torch.randn(1, 30, 7).to(device)
            inference_outputs = model(test_images, test_input_actions)
            
            print("æ¨ç†è¾“å‡ºå½¢çŠ¶:")
            for key, value in inference_outputs.items():
                if isinstance(value, torch.Tensor):
                    print(f"  {key}: {value.shape}")
            
            print("âœ… æ¨ç†æ¨¡å¼æµ‹è¯•æˆåŠŸ!")
            
        except Exception as e:
            print(f"âŒ æ¨ç†æ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    # ç»˜åˆ¶æŸå¤±æ›²çº¿
    plt.figure(figsize=(10, 6))
    plt.plot(loss_history)
    plt.title('VLAæ¨¡å‹è®­ç»ƒæŸå¤±æ›²çº¿')
    plt.xlabel('è®­ç»ƒæ­¥æ•°')
    plt.ylabel('æŸå¤±å€¼')
    plt.grid(True)
    plt.savefig('c:\\DiskD\\trae_doc\\VLA\\training_loss_curve.png')
    plt.show()
    
    print(f"\nâœ… æ¨¡å‹è®­ç»ƒéªŒè¯å®Œæˆ!")
    print(f"æœ€ç»ˆæŸå¤±: {loss_history[-1]:.4f}")
    print(f"æŸå¤±æ›²çº¿å·²ä¿å­˜åˆ°: c:\\DiskD\\trae_doc\\VLA\\training_loss_curve.png")
    
    return True

def test_model_components():
    """
    æµ‹è¯•æ¨¡å‹å„ä¸ªç»„ä»¶
    """
    print("\næµ‹è¯•æ¨¡å‹ç»„ä»¶...")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    model = RobotUniADModel(
        num_seg_classes=10,
        num_det_classes=10,
        num_seg_queries=50,
        num_det_queries=50,
        num_points=3,
        action_dim=7,
        seq_len=30,
        image_size=(640, 480)
    ).to(device)
    
    # æµ‹è¯•è§†è§‰ç¼–ç å™¨
    print("1. æµ‹è¯•è§†è§‰ç¼–ç å™¨...")
    test_images = torch.randn(2, 2, 3, 640, 480).to(device)
    try:
        Vfeatures_list, spatial_shapes, level_start_index, valid_ratios = model.visual_encoder(test_images)
        print(f"   âœ… è§†è§‰ç‰¹å¾å½¢çŠ¶: {[f.shape for f in Vfeatures_list]}")
    except Exception as e:
        print(f"   âŒ è§†è§‰ç¼–ç å™¨é”™è¯¯: {e}")
        return False
    
    # æµ‹è¯•æ—¶ç©ºèåˆ
    print("2. æµ‹è¯•æ—¶ç©ºèåˆ...")
    try:
        Vfeatures = model.temporal_spatial_fusion(Vfeatures_list)
        print(f"   âœ… èåˆç‰¹å¾å½¢çŠ¶: {Vfeatures.shape}")
    except Exception as e:
        print(f"   âŒ æ—¶ç©ºèåˆé”™è¯¯: {e}")
        return False
    
    # æµ‹è¯•ç»Ÿä¸€Transformer
    print("3. æµ‹è¯•ç»Ÿä¸€Transformer...")
    try:
        unified_outputs = model.unified_transformer(
            Vfeatures, spatial_shapes, level_start_index, valid_ratios
        )
        print(f"   âœ… ç»Ÿä¸€è¾“å‡ºé”®: {list(unified_outputs.keys())}")
    except Exception as e:
        print(f"   âŒ ç»Ÿä¸€Transformeré”™è¯¯: {e}")
        return False
    
    # æµ‹è¯•è‡ªå›å½’è½¨è¿¹ç”Ÿæˆ
    print("4. æµ‹è¯•è‡ªå›å½’è½¨è¿¹ç”Ÿæˆ...")
    try:
        test_input_actions = torch.randn(2, 30, 7).to(device)
        test_target_actions = torch.randn(2, 30, 7).to(device)
        
        trajectory_output = model.trajectory_autoregressive(
            test_input_actions,
            unified_outputs['seg_features'],
            unified_outputs['det_features'],
            Vfeatures,
            unified_outputs['point_features'],
            target_actions=test_target_actions
        )
        print(f"   âœ… è½¨è¿¹è¾“å‡ºå½¢çŠ¶: {trajectory_output.shape}")
    except Exception as e:
        print(f"   âŒ è‡ªå›å½’è½¨è¿¹ç”Ÿæˆé”™è¯¯: {e}")
        return False
    
    # æµ‹è¯•è‡ªå›å½’æ¨ç†æ¨¡å¼
    print("5. æµ‹è¯•è‡ªå›å½’æ¨ç†æ¨¡å¼...")
    try:
        model.eval()
        with torch.no_grad():
            inference_output = model.trajectory_autoregressive.generate(
                test_input_actions,
                unified_outputs['seg_features'],
                unified_outputs['det_features'],
                Vfeatures,
                unified_outputs['point_features']
            )
            print(f"   âœ… æ¨ç†è¾“å‡ºå½¢çŠ¶: {inference_output.shape}")
    except Exception as e:
        print(f"   âŒ è‡ªå›å½’æ¨ç†æ¨¡å¼é”™è¯¯: {e}")
        return False
    
    print("âœ… æ‰€æœ‰ç»„ä»¶æµ‹è¯•é€šè¿‡!")
    return True

def test_autoregressive_generation():
    """
    ä¸“é—¨æµ‹è¯•è‡ªå›å½’ç”ŸæˆåŠŸèƒ½
    """
    print("\næµ‹è¯•è‡ªå›å½’ç”ŸæˆåŠŸèƒ½...")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    model = RobotUniADModel(
        num_seg_classes=10,
        num_det_classes=10,
        num_seg_queries=50,
        num_det_queries=50,
        num_points=3,
        action_dim=7,
        seq_len=30,
        image_size=(640, 480)
    ).to(device)
    
    model.eval()
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    test_images = torch.randn(1, 2, 3, 640, 480).to(device)
    test_input_actions = torch.randn(1, 30, 7).to(device)
    
    print("1. æµ‹è¯•å®Œæ•´æ¨ç†æµç¨‹...")
    try:
        with torch.no_grad():
            outputs = model(test_images, test_input_actions)
            trajectory_actions = outputs['trajectory_actions']
            print(f"   âœ… ç”Ÿæˆçš„åŠ¨ä½œåºåˆ—å½¢çŠ¶: {trajectory_actions.shape}")
            print(f"   âœ… åŠ¨ä½œå€¼èŒƒå›´: [{trajectory_actions.min().item():.3f}, {trajectory_actions.max().item():.3f}]")
    except Exception as e:
        print(f"   âŒ å®Œæ•´æ¨ç†æµç¨‹é”™è¯¯: {e}")
        return False
    
    print("2. æµ‹è¯•æ‰¹é‡ç”Ÿæˆ...")
    try:
        batch_images = torch.randn(4, 2, 3, 640, 480).to(device)
        batch_input_actions = torch.randn(4, 30, 7).to(device)
        
        with torch.no_grad():
            batch_outputs = model(batch_images, batch_input_actions)
            batch_trajectory = batch_outputs['trajectory_actions']
            print(f"   âœ… æ‰¹é‡ç”Ÿæˆå½¢çŠ¶: {batch_trajectory.shape}")
    except Exception as e:
        print(f"   âŒ æ‰¹é‡ç”Ÿæˆé”™è¯¯: {e}")
        return False
    
    print("âœ… è‡ªå›å½’ç”ŸæˆåŠŸèƒ½æµ‹è¯•é€šè¿‡!")
    return True

if __name__ == "__main__":
    print("=" * 60)
    print("VLAè‡ªå›å½’æ¨¡å‹è®­ç»ƒéªŒè¯è„šæœ¬")
    print("=" * 60)
    
    # æµ‹è¯•æ¨¡å‹ç»„ä»¶
    if test_model_components():
        # æµ‹è¯•è‡ªå›å½’ç”Ÿæˆ
        if test_autoregressive_generation():
            # æµ‹è¯•å®Œæ•´è®­ç»ƒæµç¨‹
            success = test_model_training()
            
            if success:
                print("\nğŸ‰ VLAè‡ªå›å½’æ¨¡å‹è®­ç»ƒéªŒè¯æˆåŠŸ! æ¨¡å‹å¯ä»¥æ­£å¸¸è®­ç»ƒã€‚")
            else:
                print("\nâŒ VLAæ¨¡å‹è®­ç»ƒéªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
        else:
            print("\nâŒ è‡ªå›å½’ç”ŸæˆåŠŸèƒ½æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹å®šä¹‰ã€‚")
    else:
        print("\nâŒ æ¨¡å‹ç»„ä»¶æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹å®šä¹‰ã€‚")
